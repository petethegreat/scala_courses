\part{Program Design}
\chapter{more with for}
\section{queries with for}

For expresions in scala can be likened to queries in an RDBMS.

\begin{lstlisting}
for (b <-books, a<- b.authors if a.startsWith "Bird," ) yield b.title

for { 
	b1 <- books
	b2 <- books
	if b1.title < b2.title
	a1 <- b1.authors
	a2 <- b2.authors
	if a1 == a2
	} yield a1
\end{lstlisting}

If the author has written 3 books, they will be printed 3 times.

\section{translating for-expressions}
For expressions are pretty handy. For expressions can generally be translated into expressions based on flatmap, map, and filter. Conversely, all of these functions can be defined in terms of for - 
\begin{lstlisting}
def mapFun[T,U](xs: List[T], f: T => U) : List[U] = for (x <- xs) yield f(x)

def flatMapFun[T,U]( xs:List[T], f: T => List[U]): List[U] = for (x <- xs, y <- f(x)) yield y

def filterFun[T](xs: List[T], f: T => Boolean): List[T] = for (x <-xs if f(x)) yield x

\end{lstlisting}

Scala translates for expressions into expressions based on map, flatmap and filter.

A really simple for-expression
\begin{lstlisting}
for (x <-e1) yield e2
\end{lstlisting}
can be translated to
\begin{lstlisting}
e1.map( x => e2)
\end{lstlisting}

Expressions of the form \lstinline|for (x <-e1 if f; s) yield e2|, where f is a filter and s is a (potentially empty) arbitrary sequence of generators and filters can be translated to 
\begin{lstlisting}
for (x<- e1.withFilter(x => f) ; s ) yield e2
\end{lstlisting}
withfilter is a lazy (i.e. smarter) implementation of filter. It does not create a new (intermediate) collection. The above expression is still contains a for expression, but we have removed one element (the if).

Cases containing more than one leading generator can be translated using flatmap
\begin{lstlisting}
for (x <-e1 ; y<-e2 ; s) yield e3
\end{lstlisting}
can be translated to 
\begin{lstlisting}
e1.flatMap(x => for (y <-e2 ; s) yield e3
\end{lstlisting}

In all of these cases, we are removing one element from the for expression. Thus an arbitrary expression can be reduced to a sequence of maps and flatmaps.

\begin{lstlisting}
for { 
	i <- 1 to N
	j <- 1 to i
	if isPrime(i + j)
} yield (i, j)
\end{lstlisting}

can be rewritten as
\begin{lstlisting}
//(1 until N).flatMap(i => for ( y <- 1 until i if isPrime(i,j)) yield (i,j) )

(1 until N).flatMap( i => 
	(1 until i).withFilter(j => isPrime(i + j)
	.map(j => (i,j)))
\end{lstlisting}

The for query above on books can be translated to \lstinline|books.flatmap(b => b.authors.withFilter(a => a.startswith("Bird").map(y => y.title)))|

Note that for expressions are not limited to lists//sequences/iterables. The translation only depends on the prescence of the methods map, flatmap, and withFilter. User defined types can be used in for expressions, provided these three methods are implemented.

For example, the collection books might instead be an interface to a database. Provided the methods are are implemented, for expressions can be used to query. the Scala database connection frameworks ScalaQuery and Slick make use of this.



\section{Monads}

monads must have an associated unit function, and have a flatmap method. I don't really get monads right now.

\section{Structural Induction}

Structural induction can be applied to trees.
To prove a property $P(t)$ for all trees of a certain type $t$
\begin{itemize}
	\item show that $P(l)$ holds for all leaves $l$ of a tree
	\item For each type of internal node t with subtrees $s_1, s_2 \ldots s_n$, show that
	$P(s_1)\wedge P(s_2)\wedge \ldots \wedge P(s_n)$ implies $P(t)$ 
\end{itemize}

if the property holds on all of the tree's subtrees, then it holds on the tree


consider the implementation of IntSets

\begin{lstlisting}
abstract class IntSet {
	def incl(x: Int) : IntSet
	def contains(x: Int): Boolean
}

object Empty extends IntSet {
	def contains(x: Int): Boolean = false
	def incl(x: Int): IntSet = NonEmpty(x, Empty, Empty)
}

case class NonEmpty(elem: Int, left: IntSet, right: IntSet) extends IntSet {
	def contains(x: Int): Boolean = 
		if (x < elem) left contains x
		else if (x > elem) right contains x
		else true
	def incl(x: Int): IntSet = 
		if  (x < elem) NonEmpty(elem, left incl x, right)
		else if (x > elem) NonEmpty(elem, left, right incl x)
		else this
}
\end{lstlisting}

how do we prove the correctness of this implementation holds? 
consider the following three laws (for integers x,y and Intset s):
\begin{itemize}
	\item \lstinline|Empty contains x = false|
	\item \lstinline| (s incl x) contains x = true|
	\item \lstinline|(s incl x) contains y = s contains y|
\end{itemize}

The first law is straightforward, and can be seen to be true (Empty.contains is false). 

For the second law (proposition), we can do strutural induction. Consider the base case when $s$ is an empty set. The we would like to show that \lstinline| (Empty incl x) contains x = true|. \lstinline|Empty incl x| evaluates to \lstinline| NonEmpty(x,...)|, and contains x will evaluate to true in this case.

For the base case when $s$ is NonEmpty, assume it takes the form NonEmpty(z,l,r), where l and r are subtrees. There are two cases to consider, z == x and z != x. If z == x, then NonEmpty(x,...) incl x will return this, which contains x, so we're good. if z != x, then NonEmpty(z) incl x will contain x, so we're good.
\section{streams}

Streams are like lists, but are evaluated lazily. The tail of the stream is not evaluated until it is needed. Streams are constructed from the object Stream.empty and the constructor stream.cons.

For lists, we might have something like
\begin{lstlisting}
def listrange(lo:Int, hi: Int): List[Int] = 
	if lo >= hi Nil
	else lo::listrange(lo+1,hi)
\end{lstlisting}
For streams, we would do
\begin{lstlisting}
def StreamRange(lo:Int, hi: Int): Stream[Int] = 
	if lo >= hi Stream.empty
	else Stream.cons(lo,StreamRange(lo+1,hi))
\end{lstlisting}

The standard shorthand for the cons operator, \lstinline|::|, will always produce a list. There is an equivalent for streams, the hash operator: \lstinline|#::|, which can be used in expressions and patterns. 

\section{State}
Up untill now we've been doing this purely functionally, as much as possible.
Some things will have a state. 

Everything witha mutable state will be constructed from variables. variables are declared with \lstinline|var| instead of \lstinline|val|. Variables can have their value changed later through assignment.

When assignment is possible, then determining whether or not things are equivalent becomes more difficult. Previously, if things evaluate to the same expression, then they are equal. 

\begin{lstlisting}
val x = E; val y = E;
val x = E; val y = x;
\end{lstlisting}
The two lines above produce the same result. In both cases, x and y evaluate to E
\begin{lstlisting}
val x = new BankAccount; val y = new BankAccount;
val x = new BankAccount; val y = x;
\end{lstlisting}
In this case, the two lines give different results. In the first, two new bankaccounts are created. In the second, y is copied from x.

How do we define "the same"? Operational equivalence - Execute the definitions of x and y, followed by an arbitrary set of operations involving x and y (S), observing all results. Then, execute the definitions followed by a different sequence of operations, S', in which every occurence of y in S has been replaced by x. If the results are different, then x and y are certainly different. Else, if every possible pair of sequences (S, S') are indistinguishable, then x and y are the same.

Assignment breaks the substitution model that we have been using up until now. In general, if we are not using purely functional code, then the substitution model will not hold.

\section{Loops}

Here's a possible definition of while that can be used to constrruct loops
\begin{lstlisting}

def WHILE(condition: => Boolean)(command :=> unit): unit = 
	if condition
	{ command
		WHILE(condition)(command)
		}
	else ()
\end{lstlisting}

 \section{event simulation}

 digital circuits - states are boolean.
 Will consider inverters (NOT), AND, and OR gates.

 Half adder - takes two inputs (A and B), and has two outputs (SUM and CARRY). CARRY is equal to A AND B, while SUM is A OR B AND NOT A AND B


\begin{figure}
\begin{circuitikz}
\draw 

(2,0) node[and port] (lowerand) {} 
(2,3) node[or port] (upperor) {}

(upperor.in 1) -- ++ (-2,0)
(lowerand.in 2) -- ++ (-2,0)

(upperor.out) ++( 2,0) node[and port, anchor=in 1](upperand){}
(lowerand.out) |- ++(1,1) node[not port](middlenot){}
(middlenot.out) |- (upperand.in 2)
(upperor.out) -- (upperand.in 1)

(upperor.in 1) -- ++ (-1.25,0) |- (lowerand.in 1)
(upperor.in 2) -- ++ (-0.75,0) |- (lowerand.in 2)
(lowerand.out) -- ++ (4,0)
;

\end{circuitikz}
\caption{half adder}
\end{figure}

two half adders can be combined (with an or gate) to form a full one-bit adder

\begin{figure}
\begin{circuitikz}
\draw 

(1,0) node[fourport, label=HA1] (ha1) {} 

(ha1.4) ++ (3,0) node[fourport,t=HA2, anchor=1] (ha2) {}
(ha2.2) ++ (1,0) node[or port,t=or, anchor=in 1] (or1) {}

(ha1.1) ++ (-1,0) node[ocirc](cin){Cin}
(ha1.4) ++ (-1,0) node[ocirc](a){A}
(ha2.4) ++ (-4,0) node[ocirc](b){B}
(ha2.3) ++ (3,0) node[ocirc](sum){Sum}
(or1.out) ++ (1,0) node[ocirc](carry){Cout}


(ha1.3) -- (ha2.1)
(ha2.2) -- (or1.in 1)
(ha1.2) -| (or1.in 2)

(cin) -- (ha1.1)
(a) -- (ha1.4)
(b) -- (ha2.4)
(ha2.3) -- (sum)
(or1.out) -- (carry)

;

\end{circuitikz}
\caption{full 1-bit adder}
\end{figure}

\subsection{event handling}

Oberver pattern, also called publish/subscribe or model/view/controller. Views \textem{subscribe} to the model. When the something in the model changes, it \textem{publishes} an update, sending the update to all subscribed views. 

\begin{lstlisting}
trait Publisher {
	private var subscribers: Set[Subscriber] = Set()

	def subscribe(subscriber:Subscriber): Unit = 
		subscribers += subscriber

	def unsubscribe(subscriber:Subscriber): Unit = 
		subscribers -= subscriber

	def publish(): Unit = 
		subscribers.foreach(_.handler(this))
}
\end{lstlisting}

Our BanAccount class could extend from Publisher, and then it would be able to inform other parts of the application when changes to the balance occur

\begin{lstlinsing}
class BankAccount extends Publisher {
	private var balance = 0
	def currentBalance:Int = balance

	def deposit(amount:Int):Unit = 
		if (amount > 0) 
		{
			balance = balance + amount
			publish()
		}

	def withdraw(amount:Int):Unit = 
		if (amount > 0 && balance >= amount) {
		balance = balance - amount
		publish()
		} else throw new Error("insufficient funds")
}
\end{lstlisting }

The balance can be queried through currentBalance, and any changes (deposits/withdrawals) are published to observers
Speaking of observers

\begin{lstlisting}

class Consolidator(observed: List[BankAccount]) extends Subscriber {
	observed.foreach(_.subscribe(this))

	private var total: Int = _
	compute()

	private def compute() =
		total =  observed.map(_.currentBalance).sum

	def handler(pub: Publisher) = compute()

	def totalBalance = total

}
\end{lstlisting}

The observer pattern (good points)
\begin{itemize}
	\item is simple to set up
	\item decouples views from state
	\item allows multiple views of the same (or similar) states
\end{itemize}

but (bad points)
\begin{itemize}
	\item forces imperative style (handlers are unit functions)
	\item lots of moving parts that need to be coupled
	\item concurrency makes things complicated
\end{itemize}

\subsection{functional reactive programming}
reactive programming is reacting to a sequence of events in time.

Functionally, we aggregate an event sequence into a signal.
\begin{itemize}
	\item The signal is a value that changes over time.
	\item it is represented as a function that maps from time domain to value.
	\item instead of propagating updates to a mutable state, we define new signals in terms of existing ones.
\end{itemize}

There are two fundamental operations over signals - obtaining the value of the signal at the current time, e.g. \lstinline|mousePosition()| and defining a signal in terms of other signals -
\begin{lstlisting}

def inReactangle(LL: Position, UR: Position): Signal[Boolean] = 
Signal {
	val pos = mousePosition()
	LL <= pos && pos <= UR
}
\end{lstlisting}

Values of Signal are immutable
There is a subclass of Signal, \lstinline|Var|, that has an update operation
\begin{lstlisting}
val sig = Var(3) // signal with constant value of 3
sig.update(5) // sig now has value of 5
\end{lstlisting}

Updates can be written as assignments (syntactic sugar).
Variable signals look a bit like mutable variable, but we can map over them. If we define a signal b to be equal to 2 time a, then updates to a automatically propagate to b. With mutable variables this is not the case, b would need to be redefined after a is changed.

bank account with signals looks much simpler. no need to explicitly publish stuff.
\begin{lstlinsing}
class BankAccount {
	val balance = Var(0)
	
	def deposit(amount:Int):Unit = 
		if (amount > 0) 
		{
			balance() = balance() + amount
			// syntatic sugar for balance.update(balance() + amount)
		}

	def withdraw(amount:Int):Unit = 
		if (amount > 0 && balance() >= amount) {
		balance() = balance() - amount
		} else throw new Error("insufficient funds")
}
\end{lstlisting }


\section{more functional reactive programming}

\url{https://github.com/rohgar/scala-design-2/wiki/A-Simple-FRP-Implementation}

signals take an expression, and implement an apply method
\begin{lstlisting}
class Signal[T]( expr: => T) {
    def apply(): T = ??? 
}

object Signal {
    def apply[T] (expr: => T) = new Signal(expr)
}
\end{lstlisting}
\lstinline|Signal(expr)|will invoke the object's apply method, returning a new instance of the Signal class, with the supplied expression.

Vars extend signals, such that they can be updated. Vars implement and update method.

\begin{lstlisting}
class Var[T] (expr: => T) extends Signal[T](expr) {
    def update(expr: => T): Unit = ???
}

object Var { 
    def apply[T](expr: => T) = new Var(expr)
}

moose = Var(expr)
moose.update(expr2)
\end{lstlisting}

\subsection{Syntatic sugar}
\lstinline|moose() = expr2| is equivalent to \lstinline|moose.update(expr2)|, just as \lstilnine|moose(expr)| is syntatic sugar for \lstinline|moose.apply(expr)|.


signal maintains:
begin{itemize}
\item it's current value
\item the expression that defines the signal value
\item a set of observers - other signals that depend on value.
\end{itemize}
if signal changes, observers are re-evaluated.


How do we record dependencies?

\section{latency/asynchoronicity}
Computations can take time. 
Scala has a Try monad for exception handling. Try is an abstract class with Success and Failure case subclasses. We can iterate over stuff, and return an instance of success when it works or Failure when it does not. Then we can make use of the successes and handle the failures.

Future is another monad, Instead of handling success/failure it handles latency - the computation may be complete or ongoing (or waiting/whatever)

Really simple network stack:
\begin{lstlisting}
trait Socket {
	def readFromMemory(): Array[Byte]
	def sendToEuropet(packet: Array[Byte]): Array[Byte]
	}

val socket = Socket()
val packet = socket.readFromMemory()
val confirmation = socket.sendToEurope(packet)

\end{lstlisting}
Reading from memory takes some time, sending to Europe takes a lot of time.

\lstinline{Future[T]} is a monda that handles both Exceptions and Latency.

\begin{lstlisting}

import scala.concurrent._
import scala.concurrent.Execution.Implicits.global

trait Future[T] {
	def onComplete(callback: Try[T] => Unit)
	//(implicit executor: ExecutionContext): Unit
}
\end{lstlisting}

When the execution is complete, the callback function is invoked. Note that as the try monad is used, the computiation we are waiting for may have suceeded or failed, but this can be handled.

Javascript uses a shit-tonne of callbacks.

Our reading/sending example above can be modified to 
\begin{lstlisting}

val socket = Socket()
val packet: Future[Array[Byte]] = socket.readFromMemory()

val confirmation: Future[Array[Byte]] = packet.onComplete{
	case Sucess(p) => socket.sendToEurope(p)
	case Failure(t) => ...
	}
\end{lstlisting}

This can result in a lot of nesting. But monads are sweet, because they can be flatmapped.

The implementation of Future might look like
\begin{lstlisting}
trait Future[T] {
	def onComplete( callback: Try[T] => unit) = ...
	def flatMap[S] (f: T => Future[S]) : Future[S] = ???
}
\end{lstlisting}
How would we implement flatMap using onComplete? 

\begin{lstlisting}
trait Future[T] { self => 
	def flatMap( f: T => Future[S]): Future[S] = { 
		new Future[S]{
			def onComplete(callback: Try[S] => Unit): Unit = {
				self onComplete {
					case Success(x) => f(x).onComplete(callback)
					case Failure(e) => callback(Failure(e))
				}
			}
		}
	}
}
\end{lstlisting}

Flatmap creates a new \lstinline|Future[S]|, and defines it's onComplete method. The new future's oncomplete relies on the onComplete method of the initial Future (self). If the self computation completes sucessfully, then the mapping function f is applied and the onComplete/callback for the Future[S] is invoked.
if self's computation fails, then the failure is passed to the callback function directly.



